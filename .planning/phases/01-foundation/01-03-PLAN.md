---
phase: 01-foundation
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - src/events/__init__.py
  - src/events/base.py
  - src/events/types.py
  - src/events/bus.py
  - src/events/store.py
  - src/db/__init__.py
  - src/db/turso.py
  - src/api/health.py
  - tests/test_events.py
autonomous: true

must_haves:
  truths:
    - "Event bus routes typed events to subscribed handlers"
    - "Event bus supports async handlers"
    - "Event store persists events to database"
    - "Event store retrieves events by aggregate"
    - "Events can be published and stored in single operation"
    - "Health endpoint reports database status"
  artifacts:
    - path: "src/events/base.py"
      provides: "Base Event class with event_id, timestamp, event_type"
      contains: "class Event"
    - path: "src/events/types.py"
      provides: "Typed event definitions for domain events"
      contains: "class MeetingCreated"
    - path: "src/events/bus.py"
      provides: "Async event bus with subscribe/publish"
      contains: "class EventBus"
    - path: "src/events/store.py"
      provides: "Append-only event store"
      contains: "class EventStore"
    - path: "src/db/turso.py"
      provides: "Turso database client wrapper"
      contains: "class TursoClient"
    - path: "tests/test_events.py"
      provides: "Event infrastructure tests"
      min_lines: 100
  key_links:
    - from: "src/events/store.py"
      to: "src/db/turso.py"
      via: "database operations"
      pattern: "TursoClient"
    - from: "src/events/bus.py"
      to: "src/events/store.py"
      via: "publish_and_store method"
      pattern: "EventStore"
    - from: "src/main.py"
      to: "src/db/turso.py"
      via: "lifespan initialization"
      pattern: "TursoClient"
---

<objective>
Implement the event bus and event store infrastructure.

Purpose: Create the event-driven architecture foundation that all subsequent phases will use to decouple components and persist domain events for audit and replay.

Output: Working event bus (pub/sub), event store (append-only persistence), and database integration with passing tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create database client and event infrastructure</name>
  <files>
    src/db/__init__.py
    src/db/turso.py
    src/events/__init__.py
    src/events/base.py
    src/events/types.py
  </files>
  <action>
1. Create db directory:
   ```bash
   mkdir -p src/db src/events
   ```

2. Create src/db/__init__.py:
   ```python
   """Database layer for TPM Admin Agent."""

   from src.db.turso import TursoClient

   __all__ = ["TursoClient"]
   ```

3. Create src/db/turso.py with async database client:
   ```python
   """Turso/libSQL database client wrapper."""

   import json
   from typing import Any, Optional

   import libsql_client
   from libsql_client import ResultSet

   from src.config import settings


   class TursoClient:
       """Wrapper for Turso/libSQL async client.

       Supports both cloud Turso (with auth token) and local SQLite files.
       """

       def __init__(
           self,
           url: Optional[str] = None,
           auth_token: Optional[str] = None,
       ):
           """Initialize client with connection parameters.

           Args:
               url: Database URL. Defaults to settings.turso_database_url or local file.
               auth_token: Auth token for Turso cloud. Defaults to settings.turso_auth_token.
           """
           self.url = url or settings.turso_database_url or "file:local.db"
           self.auth_token = auth_token or settings.turso_auth_token
           self._client: Optional[libsql_client.Client] = None

       async def connect(self) -> None:
           """Establish database connection."""
           if self._client is not None:
               return

           if self.auth_token and self.url.startswith("libsql://"):
               # Cloud Turso
               self._client = libsql_client.create_client(
                   url=self.url,
                   auth_token=self.auth_token,
               )
           else:
               # Local file database
               self._client = libsql_client.create_client(url=self.url)

       async def execute(
           self,
           sql: str,
           params: Optional[list[Any]] = None,
       ) -> ResultSet:
           """Execute a SQL statement.

           Args:
               sql: SQL query with ? placeholders
               params: Query parameters

           Returns:
               ResultSet with rows and metadata
           """
           if not self._client:
               raise RuntimeError("Not connected. Call connect() first.")
           return await self._client.execute(sql, params or [])

       async def execute_batch(self, statements: list[str]) -> None:
           """Execute multiple SQL statements in a batch.

           Args:
               statements: List of SQL statements
           """
           if not self._client:
               raise RuntimeError("Not connected. Call connect() first.")
           await self._client.batch(statements)

       async def close(self) -> None:
           """Close the database connection."""
           if self._client:
               await self._client.close()
               self._client = None

       async def is_healthy(self) -> bool:
           """Check if database connection is healthy."""
           try:
               if not self._client:
                   return False
               result = await self._client.execute("SELECT 1")
               return len(result.rows) == 1
           except Exception:
               return False


   # Global client instance (initialized in app lifespan)
   db_client: Optional[TursoClient] = None


   async def get_db() -> TursoClient:
       """Get the database client instance.

       Used as FastAPI dependency.
       """
       if db_client is None:
           raise RuntimeError("Database not initialized")
       return db_client
   ```

4. Create src/events/__init__.py:
   ```python
   """Event infrastructure for TPM Admin Agent.

   Provides:
   - Event: Base class for all domain events
   - EventBus: In-process pub/sub for event routing
   - EventStore: Append-only event persistence
   """

   from src.events.base import Event
   from src.events.bus import EventBus
   from src.events.store import ConcurrencyError, EventStore
   from src.events.types import (
       ActionItemExtracted,
       DecisionExtracted,
       IssueExtracted,
       MeetingCreated,
       MeetingProcessed,
       RiskExtracted,
       TranscriptParsed,
   )

   __all__ = [
       # Base
       "Event",
       # Infrastructure
       "EventBus",
       "EventStore",
       "ConcurrencyError",
       # Event types
       "MeetingCreated",
       "TranscriptParsed",
       "MeetingProcessed",
       "ActionItemExtracted",
       "DecisionExtracted",
       "RiskExtracted",
       "IssueExtracted",
   ]
   ```

5. Create src/events/base.py with base Event class:
   ```python
   """Base Event class for all domain events."""

   from datetime import datetime, timezone
   from typing import Any, Optional
   from uuid import UUID, uuid4

   from pydantic import BaseModel, ConfigDict, Field


   class Event(BaseModel):
       """Base class for all domain events.

       Events are immutable records of things that happened.
       They are the source of truth in an event-sourced system.

       Attributes:
           event_id: Unique identifier for this event instance
           timestamp: When the event occurred
           aggregate_id: ID of the entity this event relates to (optional)
           aggregate_type: Type of the entity (e.g., "Meeting", "ActionItem")
           metadata: Additional context about the event
       """

       model_config = ConfigDict(
           frozen=True,  # Events are immutable
           str_strip_whitespace=True,
       )

       event_id: UUID = Field(
           default_factory=uuid4,
           description="Unique event identifier",
       )
       timestamp: datetime = Field(
           default_factory=lambda: datetime.now(timezone.utc),
           description="When the event occurred",
       )
       aggregate_id: Optional[UUID] = Field(
           default=None,
           description="ID of the related entity",
       )
       aggregate_type: Optional[str] = Field(
           default=None,
           description="Type of the related entity",
       )
       metadata: dict[str, Any] = Field(
           default_factory=dict,
           description="Additional event context",
       )

       @property
       def event_type(self) -> str:
           """Return the event type name (class name)."""
           return self.__class__.__name__

       def to_store_dict(self) -> dict[str, Any]:
           """Convert event to dictionary for storage.

           Returns a dict suitable for JSON serialization and database storage.
           """
           return {
               "event_id": str(self.event_id),
               "event_type": self.event_type,
               "timestamp": self.timestamp.isoformat(),
               "aggregate_id": str(self.aggregate_id) if self.aggregate_id else None,
               "aggregate_type": self.aggregate_type,
               "data": self.model_dump(exclude={"event_id", "timestamp", "aggregate_id", "aggregate_type"}),
           }
   ```

6. Create src/events/types.py with typed event definitions:
   ```python
   """Typed event definitions for domain events.

   These events represent things that happen in the system:
   - MeetingCreated: A new meeting was created
   - TranscriptParsed: Transcript was parsed into utterances
   - MeetingProcessed: All extraction completed
   - ActionItemExtracted: An action item was extracted
   - DecisionExtracted: A decision was extracted
   - RiskExtracted: A risk was extracted
   - IssueExtracted: An issue was extracted
   """

   from datetime import datetime
   from typing import Optional
   from uuid import UUID

   from pydantic import Field

   from src.events.base import Event


   class MeetingCreated(Event):
       """Emitted when a new meeting is created from transcript upload."""

       aggregate_type: str = "Meeting"
       title: str = Field(description="Meeting title")
       meeting_date: datetime = Field(description="When the meeting occurred")
       participant_count: int = Field(default=0, description="Number of participants")
       transcript_filename: Optional[str] = Field(
           default=None, description="Original transcript filename"
       )


   class TranscriptParsed(Event):
       """Emitted when a transcript is successfully parsed."""

       aggregate_type: str = "Meeting"
       utterance_count: int = Field(description="Number of utterances parsed")
       speaker_count: int = Field(description="Number of unique speakers")
       duration_seconds: Optional[float] = Field(
           default=None, description="Total transcript duration"
       )


   class MeetingProcessed(Event):
       """Emitted when all extraction is complete for a meeting."""

       aggregate_type: str = "Meeting"
       action_item_count: int = Field(default=0, description="Action items extracted")
       decision_count: int = Field(default=0, description="Decisions extracted")
       risk_count: int = Field(default=0, description="Risks extracted")
       issue_count: int = Field(default=0, description="Issues extracted")
       processing_time_ms: Optional[int] = Field(
           default=None, description="Total processing time in milliseconds"
       )


   class ActionItemExtracted(Event):
       """Emitted when an action item is extracted from a transcript."""

       aggregate_type: str = "ActionItem"
       meeting_id: UUID = Field(description="ID of source meeting")
       action_item_id: UUID = Field(description="ID of the created action item")
       description: str = Field(description="Action item description")
       assignee_name: Optional[str] = Field(
           default=None, description="Assigned person (as mentioned)"
       )
       due_date: Optional[datetime] = Field(
           default=None, description="Due date if specified"
       )
       confidence: float = Field(
           default=1.0, ge=0.0, le=1.0, description="Extraction confidence"
       )


   class DecisionExtracted(Event):
       """Emitted when a decision is extracted from a transcript."""

       aggregate_type: str = "Decision"
       meeting_id: UUID = Field(description="ID of source meeting")
       decision_id: UUID = Field(description="ID of the created decision")
       description: str = Field(description="Decision description")
       confidence: float = Field(
           default=1.0, ge=0.0, le=1.0, description="Extraction confidence"
       )


   class RiskExtracted(Event):
       """Emitted when a risk is extracted from a transcript."""

       aggregate_type: str = "Risk"
       meeting_id: UUID = Field(description="ID of source meeting")
       risk_id: UUID = Field(description="ID of the created risk")
       description: str = Field(description="Risk description")
       severity: str = Field(description="Severity level")
       confidence: float = Field(
           default=1.0, ge=0.0, le=1.0, description="Extraction confidence"
       )


   class IssueExtracted(Event):
       """Emitted when an issue is extracted from a transcript."""

       aggregate_type: str = "Issue"
       meeting_id: UUID = Field(description="ID of source meeting")
       issue_id: UUID = Field(description="ID of the created issue")
       description: str = Field(description="Issue description")
       priority: str = Field(description="Priority level")
       confidence: float = Field(
           default=1.0, ge=0.0, le=1.0, description="Extraction confidence"
       )
   ```
  </action>
  <verify>
    Run: `uv run python -c "from src.events import Event, MeetingCreated; from uuid import uuid4; from datetime import datetime, timezone; e = MeetingCreated(aggregate_id=uuid4(), title='Test', meeting_date=datetime.now(timezone.utc)); print(e.event_type, e.to_store_dict())"`
    Expected: Prints "MeetingCreated" and the event dictionary.
  </verify>
  <done>
    Database client and event base classes created with proper typing and serialization.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement event bus and event store</name>
  <files>
    src/events/bus.py
    src/events/store.py
    src/api/health.py
    src/main.py
  </files>
  <action>
1. Create src/events/bus.py with async event bus:
   ```python
   """Async event bus for in-process pub/sub.

   The event bus decouples event producers from consumers.
   Publishers emit events, subscribers receive events they're interested in.
   """

   import asyncio
   import logging
   from typing import Callable, Optional, Type, TypeVar

   from src.events.base import Event
   from src.events.store import EventStore

   logger = logging.getLogger(__name__)

   T = TypeVar("T", bound=Event)
   EventHandler = Callable[[Event], None] | Callable[[Event], asyncio.coroutine]


   class EventBus:
       """Simple async event bus for in-process pub/sub.

       Features:
       - Type-safe subscriptions
       - Async handler support
       - Optional persistence via EventStore
       - Error isolation (one handler failure doesn't affect others)
       """

       def __init__(self, store: Optional[EventStore] = None):
           """Initialize event bus.

           Args:
               store: Optional EventStore for persistence
           """
           self._subscribers: dict[Type[Event], list[EventHandler]] = {}
           self._store = store
           self._lock = asyncio.Lock()

       def subscribe(
           self,
           event_type: Type[T],
           handler: Callable[[T], None] | Callable[[T], asyncio.coroutine],
       ) -> None:
           """Subscribe a handler to an event type.

           Args:
               event_type: The event class to subscribe to
               handler: Function to call when event is published
           """
           if event_type not in self._subscribers:
               self._subscribers[event_type] = []
           self._subscribers[event_type].append(handler)
           logger.debug(f"Subscribed handler to {event_type.__name__}")

       def unsubscribe(
           self,
           event_type: Type[T],
           handler: EventHandler,
       ) -> None:
           """Unsubscribe a handler from an event type.

           Args:
               event_type: The event class to unsubscribe from
               handler: The handler to remove
           """
           if event_type in self._subscribers:
               try:
                   self._subscribers[event_type].remove(handler)
                   logger.debug(f"Unsubscribed handler from {event_type.__name__}")
               except ValueError:
                   pass  # Handler wasn't subscribed

       async def publish(self, event: Event, persist: bool = False) -> None:
           """Publish an event to all subscribers.

           Args:
               event: The event to publish
               persist: Whether to persist event to store (if available)
           """
           event_type = type(event)
           handlers = self._subscribers.get(event_type, [])

           logger.debug(
               f"Publishing {event.event_type} to {len(handlers)} handler(s)"
           )

           # Persist event if requested and store is available
           if persist and self._store:
               try:
                   await self._store.append(event)
               except Exception as e:
                   logger.error(f"Failed to persist event: {e}")
                   raise

           # Run handlers concurrently
           tasks = []
           for handler in handlers:
               if asyncio.iscoroutinefunction(handler):
                   tasks.append(self._run_async_handler(handler, event))
               else:
                   tasks.append(self._run_sync_handler(handler, event))

           if tasks:
               results = await asyncio.gather(*tasks, return_exceptions=True)
               # Log any handler errors but don't re-raise
               for i, result in enumerate(results):
                   if isinstance(result, Exception):
                       logger.error(
                           f"Handler error for {event.event_type}: {result}"
                       )

       async def publish_and_store(self, event: Event) -> None:
           """Publish event and persist to store.

           Convenience method that always persists.
           """
           await self.publish(event, persist=True)

       async def _run_async_handler(
           self,
           handler: Callable[[Event], asyncio.coroutine],
           event: Event,
       ) -> None:
           """Run an async handler safely."""
           try:
               await handler(event)
           except Exception as e:
               logger.error(f"Async handler error: {e}")
               raise

       async def _run_sync_handler(
           self,
           handler: Callable[[Event], None],
           event: Event,
       ) -> None:
           """Run a sync handler in thread pool."""
           try:
               await asyncio.to_thread(handler, event)
           except Exception as e:
               logger.error(f"Sync handler error: {e}")
               raise

       def subscriber_count(self, event_type: Type[Event]) -> int:
           """Get number of subscribers for an event type."""
           return len(self._subscribers.get(event_type, []))
   ```

2. Create src/events/store.py with append-only event store:
   ```python
   """Append-only event store using Turso/libSQL.

   The event store persists all domain events for:
   - Audit trail
   - Event replay
   - Building projections
   - Debugging
   """

   import json
   import logging
   from datetime import datetime
   from typing import AsyncIterator, Optional
   from uuid import UUID

   from src.db.turso import TursoClient
   from src.events.base import Event

   logger = logging.getLogger(__name__)


   class ConcurrencyError(Exception):
       """Raised when optimistic concurrency check fails."""

       pass


   class EventStore:
       """Append-only event store using Turso/libSQL.

       Features:
       - Append-only (never update/delete)
       - Optimistic concurrency control
       - Event retrieval by aggregate
       - Event replay support
       """

       def __init__(self, client: TursoClient):
           """Initialize event store.

           Args:
               client: Database client for persistence
           """
           self.client = client

       async def init_schema(self) -> None:
           """Create the events table if it doesn't exist."""
           await self.client.execute("""
               CREATE TABLE IF NOT EXISTS events (
                   id INTEGER PRIMARY KEY AUTOINCREMENT,
                   event_id TEXT UNIQUE NOT NULL,
                   event_type TEXT NOT NULL,
                   aggregate_id TEXT,
                   aggregate_type TEXT,
                   event_data TEXT NOT NULL,
                   timestamp TEXT NOT NULL,
                   version INTEGER,
                   created_at TEXT DEFAULT CURRENT_TIMESTAMP
               )
           """)
           await self.client.execute("""
               CREATE INDEX IF NOT EXISTS idx_events_aggregate
               ON events(aggregate_type, aggregate_id, version)
           """)
           await self.client.execute("""
               CREATE INDEX IF NOT EXISTS idx_events_type
               ON events(event_type)
           """)
           await self.client.execute("""
               CREATE INDEX IF NOT EXISTS idx_events_timestamp
               ON events(timestamp)
           """)
           logger.info("Event store schema initialized")

       async def append(
           self,
           event: Event,
           expected_version: Optional[int] = None,
       ) -> None:
           """Append an event to the store.

           Args:
               event: The event to store
               expected_version: For optimistic concurrency (optional)

           Raises:
               ConcurrencyError: If expected_version doesn't match
           """
           store_dict = event.to_store_dict()
           event_data = json.dumps(store_dict["data"], default=str)

           # Handle optimistic concurrency if aggregate_id is set
           version = None
           if event.aggregate_id and expected_version is not None:
               result = await self.client.execute(
                   "SELECT MAX(version) FROM events WHERE aggregate_id = ?",
                   [str(event.aggregate_id)],
               )
               current_version = result.rows[0][0] if result.rows[0][0] else 0
               if current_version != expected_version:
                   raise ConcurrencyError(
                       f"Expected version {expected_version}, got {current_version}"
                   )
               version = current_version + 1

           await self.client.execute(
               """INSERT INTO events
                  (event_id, event_type, aggregate_id, aggregate_type,
                   event_data, timestamp, version)
                  VALUES (?, ?, ?, ?, ?, ?, ?)""",
               [
                   str(event.event_id),
                   event.event_type,
                   str(event.aggregate_id) if event.aggregate_id else None,
                   event.aggregate_type,
                   event_data,
                   event.timestamp.isoformat(),
                   version,
               ],
           )
           logger.debug(f"Stored event {event.event_type} ({event.event_id})")

       async def get_events_for_aggregate(
           self,
           aggregate_id: UUID,
           from_version: int = 0,
       ) -> AsyncIterator[dict]:
           """Retrieve events for an aggregate.

           Args:
               aggregate_id: The aggregate's ID
               from_version: Start from this version (exclusive)

           Yields:
               Event dictionaries
           """
           result = await self.client.execute(
               """SELECT event_type, event_data, version, timestamp
                  FROM events
                  WHERE aggregate_id = ? AND (version > ? OR version IS NULL)
                  ORDER BY id ASC""",
               [str(aggregate_id), from_version],
           )
           for row in result.rows:
               yield {
                   "event_type": row[0],
                   "data": json.loads(row[1]),
                   "version": row[2],
                   "timestamp": row[3],
               }

       async def get_events_by_type(
           self,
           event_type: str,
           limit: int = 100,
           offset: int = 0,
       ) -> AsyncIterator[dict]:
           """Retrieve events by type.

           Args:
               event_type: Event type name (class name)
               limit: Maximum events to return
               offset: Number of events to skip

           Yields:
               Event dictionaries
           """
           result = await self.client.execute(
               """SELECT event_id, event_type, aggregate_id, event_data, timestamp
                  FROM events
                  WHERE event_type = ?
                  ORDER BY id DESC
                  LIMIT ? OFFSET ?""",
               [event_type, limit, offset],
           )
           for row in result.rows:
               yield {
                   "event_id": row[0],
                   "event_type": row[1],
                   "aggregate_id": row[2],
                   "data": json.loads(row[3]),
                   "timestamp": row[4],
               }

       async def get_all_events(
           self,
           since: Optional[datetime] = None,
           limit: int = 1000,
       ) -> AsyncIterator[dict]:
           """Retrieve all events, optionally since a timestamp.

           Args:
               since: Only return events after this timestamp
               limit: Maximum events to return

           Yields:
               Event dictionaries
           """
           if since:
               result = await self.client.execute(
                   """SELECT event_id, event_type, aggregate_id, event_data, timestamp
                      FROM events
                      WHERE timestamp > ?
                      ORDER BY id ASC
                      LIMIT ?""",
                   [since.isoformat(), limit],
               )
           else:
               result = await self.client.execute(
                   """SELECT event_id, event_type, aggregate_id, event_data, timestamp
                      FROM events
                      ORDER BY id ASC
                      LIMIT ?""",
                   [limit],
               )
           for row in result.rows:
               yield {
                   "event_id": row[0],
                   "event_type": row[1],
                   "aggregate_id": row[2],
                   "data": json.loads(row[3]),
                   "timestamp": row[4],
               }

       async def count_events(self, event_type: Optional[str] = None) -> int:
           """Count events, optionally by type.

           Args:
               event_type: Optional event type to filter by

           Returns:
               Number of events
           """
           if event_type:
               result = await self.client.execute(
                   "SELECT COUNT(*) FROM events WHERE event_type = ?",
                   [event_type],
               )
           else:
               result = await self.client.execute("SELECT COUNT(*) FROM events")
           return result.rows[0][0]
   ```

3. Update src/api/health.py to include database health check:
   ```python
   """Health check endpoints for monitoring and orchestration."""

   from datetime import datetime, timezone

   from fastapi import APIRouter, Request
   from pydantic import BaseModel

   from src.config import settings

   router = APIRouter(prefix="/health", tags=["health"])


   class HealthResponse(BaseModel):
       """Response model for health check."""

       status: str
       timestamp: datetime
       version: str
       environment: str


   class LivenessResponse(BaseModel):
       """Response model for liveness probe."""

       status: str


   class ReadinessResponse(BaseModel):
       """Response model for readiness probe."""

       status: str
       checks: dict[str, str]


   @router.get("/", response_model=HealthResponse)
   async def health_check() -> HealthResponse:
       """Basic health check endpoint."""
       return HealthResponse(
           status="healthy",
           timestamp=datetime.now(timezone.utc),
           version=settings.app_version,
           environment=settings.app_env,
       )


   @router.get("/live", response_model=LivenessResponse)
   async def liveness() -> LivenessResponse:
       """Liveness probe - app is running."""
       return LivenessResponse(status="alive")


   @router.get("/ready", response_model=ReadinessResponse)
   async def readiness(request: Request) -> ReadinessResponse:
       """Readiness probe - app can serve traffic.

       Checks:
       - API is responding
       - Database is connected and healthy
       """
       checks: dict[str, str] = {"api": "ok"}

       # Check database if available
       db = getattr(request.app.state, "db", None)
       if db:
           try:
               is_healthy = await db.is_healthy()
               checks["database"] = "ok" if is_healthy else "failed"
           except Exception:
               checks["database"] = "failed"
       else:
           checks["database"] = "not_configured"

       status = "ready" if all(v == "ok" for v in checks.values()) else "not_ready"
       return ReadinessResponse(status=status, checks=checks)
   ```

4. Update src/main.py to initialize database and event infrastructure:
   ```python
   """FastAPI application entry point."""

   import logging
   from contextlib import asynccontextmanager
   from typing import AsyncGenerator

   from fastapi import FastAPI

   from src.api.router import api_router
   from src.config import settings
   from src.db.turso import TursoClient, db_client
   from src.events.bus import EventBus
   from src.events.store import EventStore

   # Configure logging
   logging.basicConfig(
       level=getattr(logging, settings.log_level.upper()),
       format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
   )
   logger = logging.getLogger(__name__)


   @asynccontextmanager
   async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
       """Application lifespan management.

       Startup:
       - Initialize database connection
       - Initialize event store schema
       - Initialize event bus

       Shutdown:
       - Close database connection
       """
       import src.db.turso as turso_module

       # Startup
       logger.info("Starting TPM Admin Agent...")

       # Initialize database
       db = TursoClient()
       await db.connect()
       app.state.db = db
       turso_module.db_client = db
       logger.info(f"Database connected: {db.url}")

       # Initialize event store
       event_store = EventStore(db)
       await event_store.init_schema()
       app.state.event_store = event_store
       logger.info("Event store initialized")

       # Initialize event bus with store
       event_bus = EventBus(store=event_store)
       app.state.event_bus = event_bus
       logger.info("Event bus initialized")

       yield

       # Shutdown
       logger.info("Shutting down TPM Admin Agent...")
       await db.close()
       logger.info("Database connection closed")


   app = FastAPI(
       title=settings.app_name,
       description="Meeting intelligence automation for TPMs",
       version=settings.app_version,
       lifespan=lifespan,
   )

   app.include_router(api_router)


   if __name__ == "__main__":
       import uvicorn

       uvicorn.run(
           "src.main:app",
           host="0.0.0.0",
           port=8000,
           reload=True,
       )
   ```
  </action>
  <verify>
    Run: `uv run uvicorn src.main:app --host 0.0.0.0 --port 8000 &`
    Wait 3 seconds, then:
    Run: `curl http://localhost:8000/health/ready`
    Expected: {"status":"ready","checks":{"api":"ok","database":"ok"}}
    Kill the server after verification.
  </verify>
  <done>
    Event bus and event store implemented, database initialized on startup, health check reports database status.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create comprehensive event tests</name>
  <files>
    tests/test_events.py
  </files>
  <action>
1. Create tests/test_events.py:
   ```python
   """Tests for event infrastructure."""

   import asyncio
   from datetime import datetime, timezone
   from uuid import uuid4

   import pytest

   from src.db.turso import TursoClient
   from src.events import (
       ActionItemExtracted,
       ConcurrencyError,
       Event,
       EventBus,
       EventStore,
       MeetingCreated,
       MeetingProcessed,
   )


   class TestEvent:
       """Tests for base Event class."""

       def test_creates_with_defaults(self) -> None:
           """Event generates event_id and timestamp."""

           class TestEvent(Event):
               message: str

           e = TestEvent(message="test")
           assert e.event_id is not None
           assert e.timestamp is not None
           assert e.event_type == "TestEvent"

       def test_is_immutable(self) -> None:
           """Events are frozen (immutable)."""

           class TestEvent(Event):
               message: str

           e = TestEvent(message="test")
           with pytest.raises(Exception):  # ValidationError for frozen model
               e.message = "changed"

       def test_to_store_dict(self) -> None:
           """Event converts to storage dictionary."""
           aggregate_id = uuid4()
           e = MeetingCreated(
               aggregate_id=aggregate_id,
               title="Test Meeting",
               meeting_date=datetime.now(timezone.utc),
               participant_count=5,
           )
           d = e.to_store_dict()
           assert d["event_type"] == "MeetingCreated"
           assert d["aggregate_id"] == str(aggregate_id)
           assert "title" in d["data"]


   class TestEventTypes:
       """Tests for typed event definitions."""

       def test_meeting_created(self) -> None:
           """MeetingCreated event has required fields."""
           e = MeetingCreated(
               aggregate_id=uuid4(),
               title="Weekly Standup",
               meeting_date=datetime.now(timezone.utc),
           )
           assert e.aggregate_type == "Meeting"
           assert e.title == "Weekly Standup"

       def test_action_item_extracted(self) -> None:
           """ActionItemExtracted event has required fields."""
           meeting_id = uuid4()
           action_id = uuid4()
           e = ActionItemExtracted(
               aggregate_id=action_id,
               meeting_id=meeting_id,
               action_item_id=action_id,
               description="Review the PR",
               assignee_name="Alice",
               confidence=0.95,
           )
           assert e.meeting_id == meeting_id
           assert e.confidence == 0.95

       def test_meeting_processed(self) -> None:
           """MeetingProcessed event captures counts."""
           e = MeetingProcessed(
               aggregate_id=uuid4(),
               action_item_count=3,
               decision_count=2,
               risk_count=1,
               issue_count=0,
               processing_time_ms=1500,
           )
           assert e.action_item_count == 3
           assert e.processing_time_ms == 1500


   class TestEventBus:
       """Tests for EventBus."""

       @pytest.mark.asyncio
       async def test_subscribe_and_publish(self) -> None:
           """Event bus delivers events to subscribers."""
           bus = EventBus()
           received = []

           async def handler(event: MeetingCreated) -> None:
               received.append(event)

           bus.subscribe(MeetingCreated, handler)

           event = MeetingCreated(
               aggregate_id=uuid4(),
               title="Test",
               meeting_date=datetime.now(timezone.utc),
           )
           await bus.publish(event)

           assert len(received) == 1
           assert received[0].title == "Test"

       @pytest.mark.asyncio
       async def test_multiple_subscribers(self) -> None:
           """Multiple subscribers all receive events."""
           bus = EventBus()
           results = {"handler1": [], "handler2": []}

           async def handler1(event: MeetingCreated) -> None:
               results["handler1"].append(event)

           async def handler2(event: MeetingCreated) -> None:
               results["handler2"].append(event)

           bus.subscribe(MeetingCreated, handler1)
           bus.subscribe(MeetingCreated, handler2)

           await bus.publish(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               )
           )

           assert len(results["handler1"]) == 1
           assert len(results["handler2"]) == 1

       @pytest.mark.asyncio
       async def test_sync_handler(self) -> None:
           """Sync handlers work via thread pool."""
           bus = EventBus()
           received = []

           def sync_handler(event: MeetingCreated) -> None:
               received.append(event)

           bus.subscribe(MeetingCreated, sync_handler)

           await bus.publish(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               )
           )

           assert len(received) == 1

       @pytest.mark.asyncio
       async def test_type_isolation(self) -> None:
           """Handlers only receive events of subscribed type."""
           bus = EventBus()
           meeting_events = []
           action_events = []

           async def meeting_handler(event: MeetingCreated) -> None:
               meeting_events.append(event)

           async def action_handler(event: ActionItemExtracted) -> None:
               action_events.append(event)

           bus.subscribe(MeetingCreated, meeting_handler)
           bus.subscribe(ActionItemExtracted, action_handler)

           await bus.publish(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               )
           )

           assert len(meeting_events) == 1
           assert len(action_events) == 0

       @pytest.mark.asyncio
       async def test_unsubscribe(self) -> None:
           """Unsubscribed handlers don't receive events."""
           bus = EventBus()
           received = []

           async def handler(event: MeetingCreated) -> None:
               received.append(event)

           bus.subscribe(MeetingCreated, handler)
           bus.unsubscribe(MeetingCreated, handler)

           await bus.publish(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               )
           )

           assert len(received) == 0

       def test_subscriber_count(self) -> None:
           """Can count subscribers for event type."""
           bus = EventBus()

           async def h1(e: MeetingCreated) -> None:
               pass

           async def h2(e: MeetingCreated) -> None:
               pass

           assert bus.subscriber_count(MeetingCreated) == 0
           bus.subscribe(MeetingCreated, h1)
           assert bus.subscriber_count(MeetingCreated) == 1
           bus.subscribe(MeetingCreated, h2)
           assert bus.subscriber_count(MeetingCreated) == 2


   class TestEventStore:
       """Tests for EventStore with in-memory SQLite."""

       @pytest.fixture
       async def store(self) -> EventStore:
           """Create event store with in-memory database."""
           client = TursoClient(url="file::memory:")
           await client.connect()
           store = EventStore(client)
           await store.init_schema()
           return store

       @pytest.mark.asyncio
       async def test_append_event(self, store: EventStore) -> None:
           """Can append an event to the store."""
           event = MeetingCreated(
               aggregate_id=uuid4(),
               title="Test Meeting",
               meeting_date=datetime.now(timezone.utc),
           )
           await store.append(event)
           count = await store.count_events()
           assert count == 1

       @pytest.mark.asyncio
       async def test_get_events_for_aggregate(self, store: EventStore) -> None:
           """Can retrieve events for an aggregate."""
           aggregate_id = uuid4()

           # Append multiple events for same aggregate
           await store.append(
               MeetingCreated(
                   aggregate_id=aggregate_id,
                   title="Meeting 1",
                   meeting_date=datetime.now(timezone.utc),
               )
           )
           await store.append(
               MeetingProcessed(
                   aggregate_id=aggregate_id,
                   action_item_count=2,
               )
           )

           # Append event for different aggregate
           await store.append(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Meeting 2",
                   meeting_date=datetime.now(timezone.utc),
               )
           )

           events = [e async for e in store.get_events_for_aggregate(aggregate_id)]
           assert len(events) == 2

       @pytest.mark.asyncio
       async def test_get_events_by_type(self, store: EventStore) -> None:
           """Can retrieve events by type."""
           await store.append(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Meeting 1",
                   meeting_date=datetime.now(timezone.utc),
               )
           )
           await store.append(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Meeting 2",
                   meeting_date=datetime.now(timezone.utc),
               )
           )
           await store.append(
               MeetingProcessed(aggregate_id=uuid4(), action_item_count=1)
           )

           events = [e async for e in store.get_events_by_type("MeetingCreated")]
           assert len(events) == 2

       @pytest.mark.asyncio
       async def test_count_events(self, store: EventStore) -> None:
           """Can count events with optional type filter."""
           await store.append(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               )
           )
           await store.append(
               MeetingProcessed(aggregate_id=uuid4(), action_item_count=1)
           )

           assert await store.count_events() == 2
           assert await store.count_events("MeetingCreated") == 1
           assert await store.count_events("MeetingProcessed") == 1

       @pytest.mark.asyncio
       async def test_concurrency_control(self, store: EventStore) -> None:
           """Optimistic concurrency control works."""
           aggregate_id = uuid4()

           # First event with version check
           await store.append(
               MeetingCreated(
                   aggregate_id=aggregate_id,
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               ),
               expected_version=0,
           )

           # Second event expecting version 1
           await store.append(
               MeetingProcessed(
                   aggregate_id=aggregate_id,
                   action_item_count=1,
               ),
               expected_version=1,
           )

           # Third event with wrong version should fail
           with pytest.raises(ConcurrencyError):
               await store.append(
                   MeetingProcessed(
                       aggregate_id=aggregate_id,
                       action_item_count=2,
                   ),
                   expected_version=1,  # Should be 2
               )


   class TestEventBusWithStore:
       """Tests for EventBus with EventStore integration."""

       @pytest.fixture
       async def bus_with_store(self) -> EventBus:
           """Create event bus with in-memory store."""
           client = TursoClient(url="file::memory:")
           await client.connect()
           store = EventStore(client)
           await store.init_schema()
           return EventBus(store=store)

       @pytest.mark.asyncio
       async def test_publish_and_store(self, bus_with_store: EventBus) -> None:
           """publish_and_store persists event."""
           received = []

           async def handler(event: MeetingCreated) -> None:
               received.append(event)

           bus_with_store.subscribe(MeetingCreated, handler)

           await bus_with_store.publish_and_store(
               MeetingCreated(
                   aggregate_id=uuid4(),
                   title="Test",
                   meeting_date=datetime.now(timezone.utc),
               )
           )

           # Handler received event
           assert len(received) == 1

           # Event was stored
           count = await bus_with_store._store.count_events()
           assert count == 1
   ```

2. Run all tests:
   ```bash
   uv run pytest tests/ -v
   ```
  </action>
  <verify>
    Run: `uv run pytest tests/test_events.py -v`
    Expected: All tests pass (approximately 15+ tests)
    Run: `uv run pytest tests/ -v`
    Expected: All tests pass (model tests + API tests + event tests)
  </verify>
  <done>
    Comprehensive event infrastructure tests pass, validating event bus, event store, and their integration.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `uv run pytest tests/ -v` - all tests pass (models + API + events)
2. `uv run uvicorn src.main:app --port 8000` - starts without errors
3. `curl http://localhost:8000/health/ready` - shows database: ok
4. Event bus routes events to handlers
5. Event store persists and retrieves events
</verification>

<success_criteria>
- Event bus implemented with subscribe/publish/unsubscribe
- Event bus supports both async and sync handlers
- Event store persists events with append-only semantics
- Event store supports optimistic concurrency control
- Event store retrieves events by aggregate and by type
- Database client initializes on app startup
- Health endpoint reports database status
- All event tests pass (15+ tests)
- All prior tests still pass (models + API)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md` following the summary template.

Include:
- All files created/modified
- Event types defined
- Test results
- Verification curl output
</output>
