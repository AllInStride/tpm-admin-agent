---
phase: 03-raid-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/config.py
  - src/services/llm_client.py
  - src/extraction/__init__.py
  - src/extraction/schemas.py
  - src/extraction/date_normalizer.py
  - tests/extraction/test_schemas.py
  - tests/extraction/test_date_normalizer.py
autonomous: true
user_setup:
  - service: anthropic
    why: "LLM API for RAID extraction"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys"

must_haves:
  truths:
    - "LLM client can make API calls to Anthropic"
    - "Extraction schemas define structured output for each RAID type"
    - "Date normalizer converts natural language dates relative to meeting date"
  artifacts:
    - path: "src/services/llm_client.py"
      provides: "Anthropic client wrapper with structured output"
      exports: ["LLMClient"]
    - path: "src/extraction/schemas.py"
      provides: "Pydantic models for LLM extraction output"
      exports: ["ExtractedActionItem", "ExtractedDecision", "ExtractedRisk", "ExtractedIssue"]
    - path: "src/extraction/date_normalizer.py"
      provides: "Date parsing with meeting context"
      exports: ["normalize_due_date"]
  key_links:
    - from: "src/services/llm_client.py"
      to: "anthropic SDK"
      via: "beta.messages.parse"
      pattern: "client\\.beta\\.messages\\.parse"
    - from: "src/extraction/date_normalizer.py"
      to: "dateparser"
      via: "parse function"
      pattern: "dateparser\\.parse"
---

<objective>
Create LLM infrastructure for RAID extraction: Anthropic client wrapper, extraction schemas, and date normalizer.

Purpose: Establish the foundational components that the RAIDExtractor service will use to extract structured data from transcripts.
Output: LLMClient service, Pydantic extraction schemas for all RAID types, date normalization utility
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-raid-extraction/03-RESEARCH.md
@src/models/action_item.py
@src/models/decision.py
@src/models/risk.py
@src/models/issue.py
@src/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and config</name>
  <files>
    - pyproject.toml
    - src/config.py
  </files>
  <action>
1. Add anthropic and dateparser dependencies:
   ```bash
   uv add anthropic dateparser
   ```

2. Update src/config.py to add Anthropic configuration:
   - anthropic_api_key: str | None (from ANTHROPIC_API_KEY env var)
   - anthropic_model: str = "claude-sonnet-4-5" (default model for extraction)
   - extraction_confidence_threshold: float = 0.5 (minimum confidence to include)
  </action>
  <verify>
    - `uv sync` completes without errors
    - `python -c "from src.config import settings; print(settings.anthropic_model)"` prints "claude-sonnet-4-5"
  </verify>
  <done>anthropic and dateparser in pyproject.toml, config has extraction settings</done>
</task>

<task type="auto">
  <name>Task 2: Create LLM client and extraction schemas</name>
  <files>
    - src/services/llm_client.py
    - src/extraction/__init__.py
    - src/extraction/schemas.py
    - src/extraction/date_normalizer.py
  </files>
  <action>
1. Create src/services/llm_client.py:
   - LLMClient class with Anthropic client via DI (or creates from settings)
   - async extract[T](prompt: str, response_model: type[T]) -> T method
   - Uses client.beta.messages.parse with betas=["structured-outputs-2025-11-13"]
   - Model from settings.anthropic_model, max_tokens=4096
   - Handle Anthropic API errors gracefully

2. Create src/extraction/__init__.py (empty or exports)

3. Create src/extraction/schemas.py with Pydantic models for LLM output:
   - ExtractedActionItem: description, assignee_name (optional), due_date_raw (optional), source_quote, confidence (0.0-1.0)
   - ExtractedDecision: description, rationale (optional), alternatives (list[str]), source_quote, confidence
   - ExtractedRisk: description, severity ("low"/"medium"/"high"/"critical"), impact (optional), mitigation (optional), owner_name (optional), source_quote, confidence
   - ExtractedIssue: description, priority ("low"/"medium"/"high"/"critical"), status ("open"), impact (optional), owner_name (optional), source_quote, confidence
   - Container models: ExtractedActionItems(items: list[ExtractedActionItem]), etc.

   Note: These schemas are for LLM output, NOT domain models. Key differences:
   - due_date_raw is string (not date) - normalized later
   - No UUIDs (LLM doesn't generate these)
   - No timestamps (added during domain conversion)

4. Create src/extraction/date_normalizer.py:
   - normalize_due_date(raw_date: str | None, meeting_date: datetime) -> date | None
   - Uses dateparser.parse with settings:
     - RELATIVE_BASE: meeting_date
     - PREFER_DATES_FROM: 'future'
     - RETURN_AS_TIMEZONE_AWARE: False
   - Returns None if raw_date is None or parsing fails
  </action>
  <verify>
    - `python -c "from src.services.llm_client import LLMClient; print('OK')"` succeeds
    - `python -c "from src.extraction.schemas import ExtractedActionItem; print(ExtractedActionItem.model_fields.keys())"` shows expected fields
    - `python -c "from src.extraction.date_normalizer import normalize_due_date; print('OK')"` succeeds
  </verify>
  <done>LLMClient wrapper exists, all extraction schemas defined, date normalizer implemented</done>
</task>

<task type="auto">
  <name>Task 3: Tests for schemas and date normalizer</name>
  <files>
    - tests/extraction/__init__.py
    - tests/extraction/test_schemas.py
    - tests/extraction/test_date_normalizer.py
  </files>
  <action>
1. Create tests/extraction/__init__.py (empty)

2. Create tests/extraction/test_schemas.py:
   - Test ExtractedActionItem validates confidence bounds (0.0-1.0)
   - Test ExtractedActionItem allows None for optional fields
   - Test ExtractedDecision with alternatives list
   - Test ExtractedRisk with severity enum values
   - Test ExtractedIssue with priority enum values
   - Test container models (ExtractedActionItems) with empty and populated lists

3. Create tests/extraction/test_date_normalizer.py:
   - Test "next Friday" relative to meeting date
   - Test "end of month" relative to meeting date
   - Test explicit date "January 25th" (should work regardless of meeting date)
   - Test None input returns None
   - Test invalid string returns None (don't raise)
   - Use fixed meeting_date (e.g., datetime(2026, 1, 18)) for deterministic tests
  </action>
  <verify>
    - `pytest tests/extraction/ -v` all tests pass
    - At least 5 tests for schemas, at least 5 tests for date normalizer
  </verify>
  <done>Schema validation tests pass, date normalizer handles relative/absolute dates correctly</done>
</task>

</tasks>

<verification>
- Dependencies installed: `uv pip list | grep -E "anthropic|dateparser"`
- Config loads: `python -c "from src.config import settings; print(settings.anthropic_model)"`
- Imports work: `python -c "from src.services.llm_client import LLMClient; from src.extraction.schemas import ExtractedActionItem; from src.extraction.date_normalizer import normalize_due_date"`
- Tests pass: `pytest tests/extraction/ -v`
</verification>

<success_criteria>
- anthropic and dateparser dependencies installed
- LLMClient wraps Anthropic structured output API
- All four RAID extraction schemas defined with confidence scores
- Date normalizer handles relative dates with meeting context
- Tests cover schema validation and date parsing edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/03-raid-extraction/03-01-SUMMARY.md`
</output>
