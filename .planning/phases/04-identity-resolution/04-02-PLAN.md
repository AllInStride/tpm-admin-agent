---
phase: 04-identity-resolution
plan: 02
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - src/identity/llm_matcher.py
  - src/identity/resolver.py
  - src/identity/__init__.py
  - src/repositories/__init__.py
  - src/repositories/mapping_repo.py
  - tests/identity/test_resolver.py
  - tests/repositories/__init__.py
  - tests/repositories/test_mapping_repo.py
autonomous: true

must_haves:
  truths:
    - "System resolves names through multi-stage pipeline (exact -> learned -> fuzzy -> LLM)"
    - "Learned mappings are persisted and reused"
    - "LLM inference handles ambiguous cases (nicknames, initials)"
    - "Resolution returns requires_review=true for confidence < 85%"
  artifacts:
    - path: "src/identity/resolver.py"
      provides: "IdentityResolver orchestrating resolution pipeline"
      exports: ["IdentityResolver"]
    - path: "src/identity/llm_matcher.py"
      provides: "LLM-assisted name inference"
      exports: ["LLMMatcher"]
    - path: "src/repositories/mapping_repo.py"
      provides: "Learned mappings persistence"
      exports: ["MappingRepository"]
  key_links:
    - from: "src/identity/resolver.py"
      to: "src/identity/fuzzy_matcher.py"
      via: "FuzzyMatcher import"
      pattern: "from src\\.identity\\.fuzzy_matcher import"
    - from: "src/identity/resolver.py"
      to: "src/repositories/mapping_repo.py"
      via: "MappingRepository import"
      pattern: "from src\\.repositories\\.mapping_repo import"
    - from: "src/identity/llm_matcher.py"
      to: "src/services/llm_client.py"
      via: "LLMClient for inference"
      pattern: "from src\\.services\\.llm_client import"
---

<objective>
Create the IdentityResolver orchestrator with learned mappings persistence and LLM-assisted inference.

Purpose: The resolver is the central service that coordinates all resolution methods. It implements the multi-stage pipeline (exact -> learned -> fuzzy -> LLM) and persists corrections for future use.
Output: IdentityResolver service, LLMMatcher for ambiguous cases, MappingRepository for persistence
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-identity-resolution/04-CONTEXT.md
@.planning/phases/04-identity-resolution/04-RESEARCH.md
@src/identity/schemas.py
@src/identity/fuzzy_matcher.py
@src/services/llm_client.py
@src/db/turso.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create MappingRepository for learned mappings</name>
  <files>
    - src/repositories/__init__.py
    - src/repositories/mapping_repo.py
    - tests/repositories/__init__.py
    - tests/repositories/test_mapping_repo.py
  </files>
  <action>
1. Create src/repositories/__init__.py with module docstring

2. Create src/repositories/mapping_repo.py:

```python
class MappingRepository:
    """Repository for persisting learned name mappings.

    Stores user-corrected name -> email mappings per project.
    Uses SQLite (via TursoClient) for persistence.
    """

    def __init__(self, db_client: TursoClient):
        self._db = db_client

    async def initialize(self) -> None:
        """Create mappings table if not exists."""
        await self._db.execute('''
            CREATE TABLE IF NOT EXISTS learned_mappings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                project_id TEXT NOT NULL,
                transcript_name TEXT NOT NULL,
                resolved_email TEXT NOT NULL,
                resolved_name TEXT NOT NULL,
                created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
                created_by TEXT,
                UNIQUE(project_id, transcript_name)
            )
        ''')
        await self._db.execute('''
            CREATE INDEX IF NOT EXISTS idx_mapping_lookup
            ON learned_mappings(project_id, transcript_name)
        ''')

    async def get_mapping(
        self,
        project_id: str,
        transcript_name: str
    ) -> tuple[str, str] | None:
        """Get learned mapping for a transcript name.

        Returns (resolved_email, resolved_name) or None.
        """

    async def save_mapping(
        self,
        project_id: str,
        transcript_name: str,
        resolved_email: str,
        resolved_name: str,
        created_by: str | None = None
    ) -> None:
        """Save a learned mapping (upsert)."""

    async def delete_mapping(
        self,
        project_id: str,
        transcript_name: str
    ) -> bool:
        """Delete a mapping. Returns True if deleted."""

    async def get_all_mappings(
        self,
        project_id: str
    ) -> list[dict]:
        """Get all mappings for a project."""
```

3. Create tests/repositories/__init__.py as empty file

4. Create tests/repositories/test_mapping_repo.py:
   - test_initialize_creates_table
   - test_save_and_get_mapping
   - test_get_nonexistent_returns_none
   - test_save_overwrites_existing (upsert behavior)
   - test_delete_mapping
   - test_get_all_mappings

Use in-memory SQLite (file::memory:) for tests.
  </action>
  <verify>
    - `pytest tests/repositories/test_mapping_repo.py -v` all tests pass
    - Table schema matches RESEARCH.md specification
  </verify>
  <done>MappingRepository persists learned name mappings with project isolation</done>
</task>

<task type="auto">
  <name>Task 2: Create LLMMatcher for ambiguous name inference</name>
  <files>
    - src/identity/llm_matcher.py
    - src/identity/__init__.py
  </files>
  <action>
Create src/identity/llm_matcher.py:

```python
class LLMMatchRequest(BaseModel):
    """Request for LLM name matching."""
    matched_email: str | None = Field(description="Email of matched person, or null if no match")
    confidence: float = Field(ge=0.0, le=1.0, description="How certain of this match")
    reasoning: str = Field(description="Brief explanation of matching logic")


class LLMMatcher:
    """LLM-assisted name inference for ambiguous cases.

    Handles cases fuzzy matching can't:
    - Nicknames (Bob -> Robert)
    - Initials (JSmith -> John Smith)
    - Transcription errors
    """

    NAME_INFERENCE_PROMPT = '''You are resolving a person's name from a meeting transcript to a project roster.

TRANSCRIPT NAME: {transcript_name}

PROJECT ROSTER:
{roster_formatted}

TASK: Determine which roster person (if any) the transcript name refers to.

RULES:
1. Consider common nicknames (Bob=Robert, Mike=Michael, Bill=William, etc.)
2. Consider initials (JSmith might be John Smith)
3. Consider typos or transcription errors
4. If no confident match, return null for matched_email

Respond with the email of the matched person (or null), your confidence (0.0-1.0), and brief reasoning.
'''

    def __init__(self, llm_client: LLMClient):
        self._llm_client = llm_client

    async def infer_match(
        self,
        transcript_name: str,
        roster: list[RosterEntry],
        fuzzy_candidates: list[tuple[RosterEntry, float]] | None = None
    ) -> ResolutionResult:
        """Use LLM to infer identity for ambiguous name.

        Args:
            transcript_name: Name as it appeared in transcript
            roster: Full project roster
            fuzzy_candidates: Top fuzzy matches if available (for context)

        Returns:
            ResolutionResult with LLM inference
        """
        roster_formatted = self._format_roster(roster)
        prompt = self.NAME_INFERENCE_PROMPT.format(
            transcript_name=transcript_name,
            roster_formatted=roster_formatted
        )

        try:
            result = await self._llm_client.extract(prompt, LLMMatchRequest)
            # Convert to ResolutionResult
            # ...
        except Exception as e:
            # Return unresolved result on LLM failure
            return ResolutionResult(
                transcript_name=transcript_name,
                resolved_email=None,
                resolved_name=None,
                confidence=0.0,
                source=ResolutionSource.LLM,
                requires_review=True
            )

    def _format_roster(self, roster: list[RosterEntry]) -> str:
        """Format roster for LLM prompt."""
        lines = []
        for entry in roster:
            alias_str = f" (aliases: {', '.join(entry.aliases)})" if entry.aliases else ""
            lines.append(f"- {entry.name} <{entry.email}>{alias_str}")
        return "\n".join(lines)
```

Update src/identity/__init__.py to export LLMMatcher
  </action>
  <verify>
    - `python -c "from src.identity import LLMMatcher"` succeeds
    - LLMMatcher has infer_match method
  </verify>
  <done>LLMMatcher handles ambiguous name resolution via LLM inference</done>
</task>

<task type="auto">
  <name>Task 3: Create IdentityResolver orchestrator with tests</name>
  <files>
    - src/identity/resolver.py
    - src/identity/__init__.py
    - tests/identity/test_resolver.py
  </files>
  <action>
Create src/identity/resolver.py:

```python
class IdentityResolver:
    """Orchestrates multi-stage identity resolution.

    Resolution pipeline (in order):
    1. Exact match (O(n) string comparison)
    2. Learned mapping lookup (O(1) with index)
    3. Fuzzy match (O(n) Jaro-Winkler)
    4. LLM inference (for ambiguous cases)
    """

    def __init__(
        self,
        fuzzy_matcher: FuzzyMatcher,
        mapping_repo: MappingRepository,
        llm_matcher: LLMMatcher | None = None,
        auto_accept_threshold: float = 0.85,
    ):
        self._fuzzy = fuzzy_matcher
        self._mappings = mapping_repo
        self._llm = llm_matcher
        self._threshold = auto_accept_threshold

    async def resolve(
        self,
        transcript_name: str,
        roster: list[RosterEntry],
        project_id: str,
    ) -> ResolutionResult:
        """Resolve a transcript name to roster entry.

        Args:
            transcript_name: Name as it appeared in transcript
            roster: Project roster entries
            project_id: Project ID for learned mappings

        Returns:
            ResolutionResult with match or requires_review=True
        """
        # Stage 1: Exact match
        exact = self._exact_match(transcript_name, roster)
        if exact:
            return ResolutionResult(
                transcript_name=transcript_name,
                resolved_email=exact.email,
                resolved_name=exact.name,
                confidence=1.0,
                source=ResolutionSource.EXACT,
                requires_review=False
            )

        # Stage 2: Learned mapping
        learned = await self._mappings.get_mapping(project_id, transcript_name)
        if learned:
            email, name = learned
            return ResolutionResult(
                transcript_name=transcript_name,
                resolved_email=email,
                resolved_name=name,
                confidence=0.95,  # High confidence for learned
                source=ResolutionSource.LEARNED,
                requires_review=False
            )

        # Stage 3: Fuzzy match
        match, score = self._fuzzy.find_best_match(transcript_name, roster)
        alternatives = self._fuzzy.find_top_matches(transcript_name, roster, limit=3)

        if match and score >= self._threshold:
            return ResolutionResult(
                transcript_name=transcript_name,
                resolved_email=match.email,
                resolved_name=match.name,
                confidence=min(score, 0.85),  # Single-source cap
                source=ResolutionSource.FUZZY,
                alternatives=[(e.name, s) for e, s in alternatives if e.email != match.email],
                requires_review=False
            )

        # Stage 4: LLM inference (if available and fuzzy gave candidates)
        if self._llm and alternatives:
            llm_result = await self._llm.infer_match(
                transcript_name, roster, alternatives
            )
            if llm_result.resolved_email:
                return llm_result

        # No match found - return for review
        return ResolutionResult(
            transcript_name=transcript_name,
            resolved_email=None,
            resolved_name=None,
            confidence=0.0,
            source=ResolutionSource.FUZZY,
            alternatives=[(e.name, s) for e, s in alternatives] if alternatives else [],
            requires_review=True
        )

    def _exact_match(
        self,
        transcript_name: str,
        roster: list[RosterEntry]
    ) -> RosterEntry | None:
        """Check for exact name match (case-insensitive)."""
        normalized = transcript_name.strip().lower()
        for entry in roster:
            if entry.name.strip().lower() == normalized:
                return entry
            if normalized in [a.strip().lower() for a in entry.aliases]:
                return entry
        return None

    async def resolve_all(
        self,
        names: list[str],
        roster: list[RosterEntry],
        project_id: str,
    ) -> list[ResolutionResult]:
        """Resolve multiple names."""
        return [
            await self.resolve(name, roster, project_id)
            for name in names
        ]

    async def learn_mapping(
        self,
        project_id: str,
        transcript_name: str,
        resolved_email: str,
        resolved_name: str,
        created_by: str | None = None
    ) -> None:
        """Save a user-confirmed mapping for future use."""
        await self._mappings.save_mapping(
            project_id=project_id,
            transcript_name=transcript_name,
            resolved_email=resolved_email,
            resolved_name=resolved_name,
            created_by=created_by
        )
```

Create tests/identity/test_resolver.py:
- test_exact_match_returns_confidence_1
- test_exact_match_via_alias
- test_learned_mapping_used_before_fuzzy
- test_fuzzy_match_above_threshold
- test_fuzzy_match_capped_at_85
- test_low_confidence_requires_review
- test_no_match_returns_requires_review_true
- test_learn_mapping_persists
- test_resolve_all_handles_multiple_names

Use mocks for MappingRepository and LLMMatcher in tests.

Update src/identity/__init__.py to export IdentityResolver
  </action>
  <verify>
    - `pytest tests/identity/test_resolver.py -v` all tests pass
    - At least 9 tests covering resolution pipeline
    - `python -c "from src.identity import IdentityResolver"` succeeds
  </verify>
  <done>IdentityResolver orchestrates multi-stage resolution with exact, learned, fuzzy, and LLM stages</done>
</task>

</tasks>

<verification>
- All identity tests pass: `pytest tests/identity/ -v`
- All repository tests pass: `pytest tests/repositories/ -v`
- Resolution pipeline works: exact -> learned -> fuzzy -> LLM
- Learned mappings persist: MappingRepository saves and retrieves
</verification>

<success_criteria>
- MappingRepository creates table and persists mappings with project isolation
- LLMMatcher prompts LLM for ambiguous name inference
- IdentityResolver implements 4-stage pipeline (exact, learned, fuzzy, LLM)
- Exact matches return confidence 1.0
- Learned mappings return confidence 0.95
- Fuzzy matches are capped at 85% (single-source cap)
- Low confidence results have requires_review=True
- learn_mapping allows user corrections to be saved
- All tests pass (15+ tests across identity and repositories)
</success_criteria>

<output>
After completion, create `.planning/phases/04-identity-resolution/04-02-SUMMARY.md`
</output>
