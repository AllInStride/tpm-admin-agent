---
phase: 09-communication-automation
plan: 02
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - src/communication/generators/__init__.py
  - src/communication/generators/base.py
  - src/communication/generators/exec_status.py
  - src/communication/generators/team_status.py
  - tests/communication/test_exec_status_generator.py
  - tests/communication/test_team_status_generator.py
autonomous: true

must_haves:
  truths:
    - "Exec status generator produces RAG indicators from data"
    - "Exec status references teams, not individual names"
    - "Exec status includes blockers with explicit ask"
    - "Team status shows completed items first"
    - "Team status includes full action item list with owners and dates"
  artifacts:
    - path: "src/communication/generators/base.py"
      provides: "BaseGenerator with LLM client and template rendering"
      exports: ["BaseGenerator"]
    - path: "src/communication/generators/exec_status.py"
      provides: "ExecStatusGenerator for COM-01"
      exports: ["ExecStatusGenerator"]
    - path: "src/communication/generators/team_status.py"
      provides: "TeamStatusGenerator for COM-02"
      exports: ["TeamStatusGenerator"]
  key_links:
    - from: "src/communication/generators/exec_status.py"
      to: "src/services/llm_client.py"
      via: "LLMClient.extract for structured output"
      pattern: "llm.*extract.*ExecStatusOutput"
    - from: "src/communication/generators/base.py"
      to: "src/communication/templates/"
      via: "Jinja2 FileSystemLoader"
      pattern: "FileSystemLoader.*templates"
---

<objective>
Implement exec status generator (COM-01) and team status generator (COM-02). Both use the same StatusData from DataAggregator but produce different outputs for their audiences.

Purpose: Fulfills COM-01 (exec audience: summary, RAG, blockers) and COM-02 (team audience: detailed action items, completed wins).
Output: Working generators that produce markdown and plain text artifacts.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-communication-automation/09-CONTEXT.md
@.planning/phases/09-communication-automation/09-RESEARCH.md
@.planning/phases/09-communication-automation/09-01-SUMMARY.md

# Infrastructure from Plan 01
@src/communication/schemas.py
@src/communication/prompts.py
@src/communication/data_aggregator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: BaseGenerator and ExecStatusGenerator (COM-01)</name>
  <files>
    src/communication/generators/__init__.py
    src/communication/generators/base.py
    src/communication/generators/exec_status.py
    tests/communication/test_exec_status_generator.py
  </files>
  <action>
Create `src/communication/generators/` module:

**base.py:**
- `BaseGenerator` abstract class:
  - `__init__(llm_client: LLMClient, template_dir: str = "src/communication/templates")`
  - Store llm_client and create Jinja2 Environment with FileSystemLoader, trim_blocks=True, lstrip_blocks=True
  - Abstract method: `async def generate(self, data: StatusData, **kwargs) -> GeneratedArtifact`
  - Helper: `_render_template(template_name: str, context: dict) -> tuple[str, str]` returns (markdown, plain_text) by rendering both .md.j2 and .txt.j2 versions
  - Helper: `_format_items(items: list[dict], max_items: int = 10) -> str` formats items for prompt context

**exec_status.py:**
- `ExecStatusGenerator(BaseGenerator)`:
  - `async def generate(self, data: StatusData, *, include_lookahead: bool = True) -> GeneratedArtifact`:
    1. Build prompt using EXEC_STATUS_PROMPT.format() with data fields
    2. Format data: limit to top 5 items per category, format meetings count
    3. Call `self._llm.extract(prompt, ExecStatusOutput)` for structured output
    4. Build template context from output.model_dump() + project_name, period, generated_at, source_meetings
    5. Render templates: `markdown, plain_text = self._render_template('exec_status', context)`
    6. Return GeneratedArtifact with type='exec_status', metadata={'rag_overall': output.overall_rag}

Per CONTEXT.md requirements:
- Half page (5-7 bullets) - limit in prompt
- Teams not individuals - instruction in prompt
- RAG indicator breakdown (overall + scope/schedule/risk) - in schema
- Blockers with explicit ask - validated in output
- Next period section - include_lookahead param

Create tests with mocked LLMClient returning valid ExecStatusOutput. Verify:
- RAG indicators present in output
- Blockers have ask field
- Markdown renders correctly
- Plain text version exists
  </action>
  <verify>
`uv run pytest tests/communication/test_exec_status_generator.py -v` passes
  </verify>
  <done>
ExecStatusGenerator produces structured exec status with RAG indicators, blockers with asks, and both markdown/plain text formats
  </done>
</task>

<task type="auto">
  <name>Task 2: TeamStatusGenerator (COM-02)</name>
  <files>
    src/communication/generators/team_status.py
    tests/communication/test_team_status_generator.py
  </files>
  <action>
**team_status.py:**
- `TeamStatusGenerator(BaseGenerator)`:
  - `async def generate(self, data: StatusData, *, include_metrics: bool = True) -> GeneratedArtifact`:
    1. Build prompt using TEAM_STATUS_PROMPT.format() with data fields
    2. Include ALL items (not truncated like exec status) - team needs full detail
    3. Call `self._llm.extract(prompt, TeamStatusOutput)` for structured output
    4. Build template context from output.model_dump()
    5. Render templates
    6. Return GeneratedArtifact with type='team_status', metadata={'item_count': len(output.open_items)}

Per CONTEXT.md requirements:
- Full list of action items with owners and due dates - no truncation
- Completed items section FIRST to celebrate wins
- Meeting notes aggregated (not per-meeting)
- More detailed than exec version

Create tests verifying:
- Completed items in output
- Open items include owner and due_date
- No truncation of items
  </action>
  <verify>
`uv run pytest tests/communication/test_team_status_generator.py -v` passes
  </verify>
  <done>
TeamStatusGenerator produces detailed team status with completed items first, full action item list with owners/dates
  </done>
</task>

</tasks>

<verification>
- [ ] `src/communication/generators/` module exists with base.py, exec_status.py, team_status.py
- [ ] `uv run pytest tests/communication/test_exec_status_generator.py tests/communication/test_team_status_generator.py -v` passes
- [ ] ExecStatusGenerator produces RAG indicators and blockers with asks
- [ ] TeamStatusGenerator shows completed items and full action item list
</verification>

<success_criteria>
- ExecStatusGenerator fulfills COM-01: summary, RAG indicators, blockers with explicit asks, teams not names
- TeamStatusGenerator fulfills COM-02: completed items first, detailed action items with owners/dates
- Both generators produce markdown and plain text outputs
- Template rendering works correctly with generated output
</success_criteria>

<output>
After completion, create `.planning/phases/09-communication-automation/09-02-SUMMARY.md`
</output>
